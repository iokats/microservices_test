= Getting Started

== Project Set UP
We created the project with the following gradle command: `gradle init`

Please, have a look into the following references:

* https://docs.gradle.org/current/samples/sample_building_java_applications_multi_project.html[Building Java Applications with libraries Sample]
* https://docs.gradle.org/current/samples/sample_convention_plugins.html[Sharing build logic between subprojects Sample]

== Docker
[.text-justify]
Docker is a platform for developing, shipping, and running applications in containers. It simplifies application
deployment by providing a consistent environment across different systems. With Docker, developers can build, test,
and deploy applications quickly and efficiently, improving collaboration and productivity.

=== Docker Architecture
[.text-justify]
Docker architecture consists of six main components: server, client, container, image, volume and registry.

[.text-justify]
1. **Docker Server** typically refers to the Docker Engine, which is the core component of the Docker platform
responsible for creating and managing containers. It provides an API and command-line interface (CLI) for interacting
with containers, allowing users to build, run, and manage containerized applications. The Docker Engine runs as a daemon
process on the host operating system and manages container lifecycle, networking, storage, and other container-related
tasks.
2. The **Docker Client** is a command-line interface (CLI) tool used to interact with the Docker Engine, allowing users to
build, run, and manage Docker containers. It sends commands to the Docker Engine via its REST API, enabling users to
perform various tasks such as creating, starting, stopping, and inspecting containers, as well as managing Docker images,
networks, volumes, and more. The Docker Client provides a simple and intuitive interface for developers and
administrators to work with Docker containers and related resources.
3. A **Docker Container** is a lightweight, standalone, and executable package that contains everything needed to run a
software application, including code, runtime, system libraries, and dependencies. Containers provide a consistent and
isolated environment for running applications, allowing them to be easily deployed across different systems without
changes. Docker containers are portable, scalable, and efficient, making them ideal for packaging, shipping, and
deploying applications in various environments, from development to production.
4. A **Docker Image** is a preconfigured template that specifies what should be included in a Docker container. Usually,
images are downloaded from websites like Docker Hub. However, it’s also possible to create a custom image with the help
of Dockerfile.
5. The **Docker Registry** is a central repository that stores and manages Docker images. It is a server-based system that
lets users store and share Docker images with others, making it easy to distribute and deploy applications. The most
notable Docker registry is Docker Hub.
6. **Docker Volumes** are a feature that allows data to persist beyond the lifespan of a container. They provide a way
to manage and store data separately from the container's filesystem, enabling data sharing between containers and between
the host machine and containers. Volumes are commonly used for storing databases, log files, configuration files, and other
persistent data in Dockerized applications. They offer flexibility, scalability, and performance benefits, making them
essential for building reliable and scalable container-based systems

=== References
* https://docs.docker.com/engine/install/ubuntu/#uninstall-docker-engine[Install Docker Engine on Ubuntu]
* https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-compose-on-ubuntu-20-04[How To Install and Use Docker Compose on Ubuntu 20.04]
* https://docs.docker.com/engine/install/linux-postinstall/[Linux post-installation steps for Docker Engine]
* https://sujanrajtuladhar.com.np/unlock-the-full-potential-of-docker-run-docker-compose-without-sudo[Unlock the Full Potential of Docker: Run Docker-Compose without Sudo]
* https://www.hostinger.com/tutorials/docker-cheat-sheet?ppc_campaign=google_search_generic_hosting_all&bidkw=defaultkeyword&lo=20215&gad_source=1&gclid=EAIaIQobChMIw4a4gIPbhAMVjZZoCR2HvQYzEAAYAiAAEgI_z_D_BwE#Clean_Up_Commands[Docker Cheat Sheet: All the Most Essential Commands in One Place]
* https://quickref.me/docker.html[Docker cheatsheet]
* https://contabo.com/blog/how-to-remove-docker-volumes-images-and-containers/[How To Remove Docker Volumes, Images and Containers]

== Persistence
https://github.com/spring-guides/tut-spring-boot-kotlin?tab=readme-ov-file#persistence-with-jpa[The Spring official guide]
says we shouldn't use kotlin data class with spring-data-jpa.

[.text-justify]
_"Here we don’t use data classes with val properties because JPA is not designed to work with immutable classes or the
methods generated automatically by data classes. If you are using other Spring Data flavor, most of them are designed
to support such constructs so you should use classes like data class User (val login: String, …) when using Spring
Data MongoDB, Spring Data JDBC, etc."_

=== Working with Spring Data Repositories
[.text-justify]
The goal of the Spring Data repository abstraction is to significantly reduce the amount of boilerplate code required to
implement data access layers for various persistence stores. For more details, please have a look into the following
reference:

* https://docs.spring.io/spring-data/data-commons/docs/current/reference/html/#repositories[Working with Spring Data Repositories]

=== No-arg compiler plugin
[.text-justify]
We added the https://kotlinlang.org/docs/no-arg-plugin.html[No-arg plugin] for generating an additional zero-argument
constructor for classes with a specific annotation. This allows the Java Persistence API (JPA) to instantiate a class,
although it doesn't have the zero-parameter constructor from Kotlin or Java point of view.

=== Enabling DuplicateKeyException in MongoDB
[.text-justify]
We have to add the following spring data configuration: `spring.data.mongodb.auto-index-creation=true`
Because in Spring Data MongoDB, automatic index creation is turned off by default.

=== Enabling the OptimisticLockingFailureException in MySQL
[.text-justify]
We have to add the following spring data configuration: `spring.jpa.hibernate.ddl-auto=create`

* https://stackoverflow.com/questions/42135114/how-does-spring-jpa-hibernate-ddl-auto-property-exactly-work-in-spring[How does spring.jpa.hibernate.ddl-auto property exactly work in Spring?]
* https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#howto.data-initialization[Spring Boot Database Initialization]
* https://aurigait.com/blog/locking-in-spring-boot/[Locking in Spring Boot]
* https://blog.mimacom.com/testing-optimistic-locking-handling-spring-boot-jpa/[Testing Optimistic Locking Handling with Spring Boot and JPA]

=== Testcontainer
[.text-justify]
Testcontainers is a Java library that provides lightweight, disposable containers for integration testing. It allows
developers to define and manage Docker containers directly within their test code, making it easy to set up isolated
environments for testing against external dependencies such as databases, message brokers, and web services. Testcontainers
automates the container lifecycle, handling container creation, startup, and teardown, ensuring consistent and reliable
test environments. It supports a wide range of containerized technologies and integrates seamlessly with popular testing
frameworks like JUnit and TestNG. Overall, Testcontainers simplifies the process of writing and running integration tests
by providing fast, reproducible, and portable test environments.

* https://testcontainers.com/[Official Site]
* https://testcontainers.com/modules/[Modules which are supported by Testcontainers]
* https://testcontainers.com/guides/[Getting Started Guides]
* https://github.com/testcontainers/testcontainers-java/tree/main/examples/spring-boot-kotlin-redis[Examples in GitHub]

== Reactive Microservice
According to 'The Reactive Manifesto' a reactive system must be Responsive, Resilient, Elastic and Message Driven.

Reactive Programming is a programming paradigm that allows developers to build applications that react to changes in data
streams and handle asynchronous events efficiently. It emphasizes declarative and event-driven programming models, making
it easier to manage complex asynchronous operations.

In summary, "asynchronous streams of data with non-blocking back pressure" describes a programming model where data
flows asynchronously between components, with operations performed non-blockingly, and back pressure applied to control
the flow of data and prevent overwhelm in downstream components. This model is commonly used in reactive programming
frameworks and systems to build scalable, responsive, and resilient applications.

=== Back-Pressure
When one component is struggling to keep-up, the system as a whole needs to respond in a sensible way. It is unacceptable
for the component under stress to fail catastrophically or to drop messages in an uncontrolled fashion. Since it can’t
cope and it can’t fail it should communicate the fact that it is under stress to upstream components and so get them to
reduce the load. This back-pressure is an important feedback mechanism that allows systems to gracefully respond to load
rather than collapse under it. The back-pressure may bubble all the way up to the user, at which point responsiveness may
degrade, but this mechanism will ensure that the system is resilient under load, and will provide information that may
allow the system itself to apply other resources to help distribute the load, see Elasticity.

=== No-Blocking

In reactive programming, non-blocking (or non-blocking I/O) refers to a programming paradigm where operations do not block
the execution thread while waiting for a result. Instead, they allow the thread to continue with other tasks or to be
returned to a thread pool for further use.

In a non-blocking system, when a piece of code initiates an I/O operation (such as reading from a file, querying a
database, or making an HTTP request), it doesn't wait for the operation to complete before moving on to the next task.
Instead, it registers a callback or a promise (depending on the programming model) and allows the thread to continue with
other work.

When the I/O operation completes, the system invokes the callback or fulfills the promise, and the associated code is
executed. This way, the thread doesn't sit idle, waiting for the I/O operation to finish, which can lead to more efficient
use of system resources and better scalability.

=== Streams
Reactive Systems rely on asynchronous message-passing to establish a boundary between components that ensures loose
coupling, isolation and location transparency. This boundary also provides the means to delegate failures as messages.
Employing explicit message-passing enables load management, elasticity, and flow control by shaping and monitoring the
message queues in the system and applying back-pressure when necessary. Location transparent messaging as a means of
communication makes it possible for the management of failure to work with the same constructs and semantics across a
cluster or within a single host. Non-blocking communication allows recipients to only consume resources while active,
leading to less system overhead.

==== Up Stream
In reactive systems, an "upstream" refers to the source of data or events in a reactive data flow. It represents the
initial producer or publisher of data, which emits data items or events that are then processed by downstream components.

==== Down Stream
In reactive systems, a "downstream" component refers to a consumer or subscriber of data or events in a reactive data
flow. It represents the components that consume or react to the data emitted by upstream components.

==== Hot Stream
In reactive systems, a "hot stream" component refers to a source of data or events that emits items regardless of whether
there are any subscribers. Hot streams are continuously producing data, and subscribers can join the stream at any time
to receive the emitted items. Unlike cold streams, hot streams do not start producing data upon subscription.

==== Cold Stream
In reactive systems, a "cold stream" component refers to a source of data or events that emits items only when there is
a subscriber. Cold streams are like traditional iterators or generators; they produce items on-demand and start emitting
data when a subscriber subscribes to them

=== References
* https://reactivemanifesto.org/pdf/the-reactive-manifesto-2.0.pdf[Reactive Manifesto]
* https://spring.io/reactive[Reactive]
* https://codersee.com/reactive-programming-in-kotlin-a-step-by-step-guide/[Reactive Programming in Kotlin: A Step-by-Step Guide]
* https://www.baeldung.com/r2dbc[R2DBC- Reactive Relational Database Connectivity]
* https://github.com/asyncer-io/r2dbc-mysql[R2DBC for MySQL]
* https://www.bezkoder.com/spring-r2dbc-mysql/[Spring Boot R2DBC MySQL Example]
* https://xebia.com/blog/spring-data-r2dbc-and-kotlin-coroutines/[Spring Data R2DBC and Kotlin Coroutines]
* https://www.baeldung.com/kotlin/spring-boot-kotlin-coroutines[Non-Blocking Spring Boot with Kotlin Coroutines]
* https://spring.io/blog/2019/04/12/going-reactive-with-spring-coroutines-and-kotlin-flow[Going Reactive with Spring, Coroutines and Kotlin Flow]
* https://spring.io/guides/tutorials/spring-webflux-kotlin-rsocket[Spring Boot with Kotlin Coroutines and RSocket]
* https://spring.io/blog/2019/04/12/going-reactive-with-spring-coroutines-and-kotlin-flow[Going Reactive with Spring, Coroutines and Kotlin Flow]
* https://codersee.com/spring-webclient-with-kotlin-coroutines/[Spring WebClient With Kotlin Coroutines]
* https://docs.spring.io/spring-data/mongodb/reference/kotlin/coroutines.html[Coroutines]
* https://dzone.com/articles/testcontainers-with-kotlin-and-spring-data-r2dbc[Testcontainers With Kotlin and Spring Data R2DBC]
* https://piotrminkowski.com/2023/07/28/reactive-spring-boot-with-webflux-r2dbc-and-postgres/[Reactive Spring Boot with WebFlux, R2DBC and Postgres]
* https://learn.microsoft.com/en-ca/archive/blogs/ddperf/parallel-scalability-isnt-childs-play-part-2-amdahls-law-vs-gunthers-law[Parallel Scalability Isn’t Child’s Play, Part 2: Amdahl’s Law vs. Gunther’s Law]

== Event-Driven Asynchronous Microservices

Even though sending asynchronous messages is preferred over synchronous API calls, it comes with challeges of its own.
We can use Spring Cloud Stream to handle some of them:

1. Consumers groups
2. Retries and dead-letter queues
3. Guaranteed orders and partitions

=== Kafka commands
Unfortunately, Kafka doesn't come with any graphical tools that can be used to inspect topic, partitions, and the messages
that are placed within them. Instead, we can run CLI commands in the Kafka Docker container.

We can use the following command for connecting to the Kafka container:
----
docker exec -it microservices_kafka_1 /bin/bash
----

If we want to see the list with the topics, we can run the following command:
----
cd /
./usr/bin/kafka-topics --bootstrap-server localhost:9092 --list
----

To see the partitions in a specific topic, for example, the products topic, run the following command:
----
cd /
./usr/bin/kafka-topics --describe --bootstrap-server localhost:9092 --topic products
----

To see all the messages in a specific topic, for example, the products topic, run the following command:
----
cd /
./usr/bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic products --from-beginning
----

To see all the messages in a specific partition, for example, partition 1 in the products topic, run the following command:
----
cd /
./usr/bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic products --from-beginning --partition 1
----

=== References
* https://zlaval.medium.com/reactive-spring-cloud-stream-in-practice-9c1e31ce8650[Reactive Spring Cloud Stream in practice]
* https://spring.io/guides/tutorials/spring-webflux-kotlin-rsocket[Spring Boot with Kotlin Coroutines and RSocket]
* https://codersee.com/apache-kafka-with-spring-boot-and-kotlin/[Apache Kafka With Spring Boot and Kotlin]